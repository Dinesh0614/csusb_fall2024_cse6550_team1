{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Interactive Mode Demo\n",
    "This is a scripting page that prints actual raw data in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "# 1. Core Packages: dotenv, requests, httpx, and pymilvus.\n",
    "# 2. LangChain and Extensions:\n",
    "#     Langchain is used for processing language chains, and Milvus is the vector database for storing embeddings.\n",
    "#     langchain: Core package.\n",
    "#     langchain-core, langchain-mistralai, langchain-cohere, langchain-milvus, langchain-community, langchain-text-splitters, and langchain-huggingface for additional modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import os\n",
    "    from dotenv import load_dotenv\n",
    "    from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "    from langchain.schema import Document\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langchain_mistralai.chat_models import ChatMistralAI\n",
    "    from langchain_milvus import Milvus\n",
    "    from langchain_community.document_loaders import WebBaseLoader, RecursiveUrlLoader\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    from langchain.chains import create_retrieval_chain\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    from pymilvus import connections, utility\n",
    "    from requests.exceptions import HTTPError\n",
    "    from httpx import HTTPStatusError\n",
    "    import sqlite3\n",
    "    import warnings\n",
    "except ImportError:\n",
    "    # Installing dependencies if not already installed\n",
    "    !pip install os requests httpx pymilvus sqlite3\n",
    "    !pip install langchain langchain-core langchain-mistralai langchain-cohere langchain-milvus langchain-community langchain-text-splitters langchain-huggingface\n",
    "    # Imports for RAG and other functionality\n",
    "    import os\n",
    "    # from dotenv import load_dotenv\n",
    "    from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "    from langchain.schema import Document\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langchain_mistralai.chat_models import ChatMistralAI\n",
    "    from langchain_milvus import Milvus\n",
    "    from langchain_community.document_loaders import WebBaseLoader, RecursiveUrlLoader\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    from langchain.chains import create_retrieval_chain\n",
    "    from langchain_huggingface import HuggingFaceEmbeddings\n",
    "    from pymilvus import connections, utility\n",
    "    from requests.exceptions import HTTPError\n",
    "    from httpx import HTTPStatusError\n",
    "    import sqlite3\n",
    "    import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display to confirm successful import\n",
    "print(\"Dependencies imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config vaiables and required functions loaded\n"
     ]
    }
   ],
   "source": [
    "COHERE_API_KEY='JPZrN72mRP2r9W5Dedo3Zk18VUS8voCHIPD7WLly'\n",
    "MISTRAL_API_KEY='aCp49AkZAXNhTUgFziRT3Q8uO0GgWjBj'\n",
    "MILVUS_URI = \"milvus/milvus_vector.db\"\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def vector_store_check(uri):\n",
    "    # Create the directory if it does not exist\n",
    "    head = os.path.split(uri)\n",
    "    os.makedirs(head[0], exist_ok=True)\n",
    "    \n",
    "    # Connect to the Milvus database\n",
    "    connections.connect(\"default\",uri=uri)\n",
    "\n",
    "    # Return True if exists, False otherwise\n",
    "    return utility.has_collection(\"IT_support\")\n",
    "\n",
    "def get_embedding_function():\n",
    "    \"\"\"\n",
    "    returns embedding function for the model\n",
    "\n",
    "    Returns:\n",
    "        embedding function\n",
    "    \"\"\"\n",
    "    embedding_function = HuggingFaceEmbeddings(model_name=MODEL_NAME)\n",
    "    return embedding_function\n",
    "\n",
    "def load_documents_from_web():\n",
    "    \"\"\"\n",
    "    Load the documents from the web and store the page contents\n",
    "\n",
    "    Returns:\n",
    "        list: The documents loaded from the web\n",
    "    \"\"\"\n",
    "    loader = RecursiveUrlLoader(\n",
    "        url=CORPUS_SOURCE,\n",
    "        prevent_outside=True,\n",
    "        base_url=CORPUS_SOURCE\n",
    "        )\n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def load_existing_db(uri=MILVUS_URI):\n",
    "    \"\"\"\n",
    "    Load an existing vector store from the local Milvus database specified by the URI.\n",
    "\n",
    "    Args:\n",
    "        uri (str, optional): Path to the local milvus db. Defaults to MILVUS_URI.\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    # Load an existing vector store\n",
    "    vector_store = Milvus(\n",
    "        collection_name=\"IT_support\",\n",
    "        embedding_function = get_embedding_function(),\n",
    "        connection_args={\"uri\": uri},\n",
    "    )\n",
    "    print(\"Vector Store Loaded\")\n",
    "    return vector_store\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split the documents into chunks\n",
    "\n",
    "    Args:\n",
    "        documents (list): The documents to split\n",
    "\n",
    "    Returns:\n",
    "        list: list of chunks of documents\n",
    "    \"\"\"\n",
    "    # Create a text splitter to split the documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,  # Split the text into chunks of 1000 characters\n",
    "        chunk_overlap=300,  # Overlap the chunks by 300 characters\n",
    "        is_separator_regex=False,  # Don't split on regex\n",
    "    )\n",
    "    # Split the documents into chunks\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "def create_vector_store(docs, embeddings, uri):\n",
    "    \"\"\"\n",
    "    This function initializes a vector store using the provided documents and embeddings.\n",
    "\n",
    "    Args:\n",
    "        docs (list): A list of documents to be stored in the vector store.\n",
    "        embeddings : A function or model that generates embeddings for the documents.\n",
    "        uri (str): Path to the local milvus db\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    # Create a new vector store and drop any existing one\n",
    "    vector_store = Milvus.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"IT_support\",\n",
    "        connection_args={\"uri\": uri},\n",
    "        drop_old=True,\n",
    "    )\n",
    "    print(\"Vector Store Created\")\n",
    "    return vector_store\n",
    "\n",
    "print(\"Config vaiables and required functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'milvus_lite'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m         vector_store \u001b[38;5;241m=\u001b[39m create_vector_store(docs, embeddings, uri)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vector_store\n\u001b[1;32m---> 28\u001b[0m \u001b[43minitialize_milvus\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[81], line 11\u001b[0m, in \u001b[0;36minitialize_milvus\u001b[1;34m(uri)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitialize_milvus\u001b[39m(uri: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39mMILVUS_URI):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    Initialize the vector store for the RAG model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m        vector_store: The vector store created\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mvector_store_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     12\u001b[0m         vector_store \u001b[38;5;241m=\u001b[39m load_existing_db(uri)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[80], line 12\u001b[0m, in \u001b[0;36mvector_store_check\u001b[1;34m(uri)\u001b[0m\n\u001b[0;32m      9\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(head[\u001b[38;5;241m0\u001b[39m], exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Connect to the Milvus database\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mconnections\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43muri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Return True if exists, False otherwise\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m utility\u001b[38;5;241m.\u001b[39mhas_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIT_support\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\pymilvus\\orm\\connections.py:379\u001b[0m, in \u001b[0;36mConnections.connect\u001b[1;34m(self, alias, user, password, db_name, token, **kwargs)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent_path\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectionConfigException(\n\u001b[0;32m    376\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpen local milvus failed, dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not exists\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmilvus_lite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mserver_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m server_manager_instance\n\u001b[0;32m    381\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass in the local path \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, and run it using milvus-lite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    382\u001b[0m local_uri \u001b[38;5;241m=\u001b[39m server_manager_instance\u001b[38;5;241m.\u001b[39mstart_and_get_uri(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muri\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'milvus_lite'"
     ]
    }
   ],
   "source": [
    "def initialize_milvus(uri: str=MILVUS_URI):\n",
    "    \"\"\"\n",
    "    Initialize the vector store for the RAG model\n",
    "\n",
    "    Args:\n",
    "        uri (str, optional): Path to the local milvus db. Defaults to MILVUS_URI.\n",
    "\n",
    "    Returns:\n",
    "        vector_store: The vector store created\n",
    "    \"\"\"\n",
    "    if vector_store_check(uri):\n",
    "        vector_store = load_existing_db(uri)\n",
    "    else:\n",
    "        embeddings = get_embedding_function()\n",
    "        print(\"Embeddings Loaded\")\n",
    "        documents = load_documents_from_web()\n",
    "        print(\"Documents Loaded\")\n",
    "        print(len(documents))\n",
    "    \n",
    "        # Split the documents into chunks\n",
    "        docs = split_documents(documents=documents)\n",
    "        print(\"Documents Splitting completed\")\n",
    "    \n",
    "        vector_store = create_vector_store(docs, embeddings, uri)\n",
    "\n",
    "    return vector_store\n",
    "\n",
    "initialize_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Created\n",
      "input_variables=['context', 'input'] template=\"\\n    Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\\n    Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\\n    Only use the information provided in the <context> tags.\\n    If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n    <context>\\n    {context}\\n    </context>\\n\\n    <question>\\n    {input}\\n    </question>\\n\\n    The response should be specific and use statistics or numbers when possible.\\n\\n    Assistant:\"\n"
     ]
    }
   ],
   "source": [
    "def create_prompt():\n",
    "    \"\"\"\n",
    "    Create a prompt template for the RAG model\n",
    "\n",
    "    Returns:\n",
    "        PromptTemplate: The prompt template for the RAG model\n",
    "    \"\"\"\n",
    "    # Define the prompt template\n",
    "    PROMPT_TEMPLATE = \"\"\"\n",
    "    Human: You are an AI assistant, and provides answers to questions by using fact based and statistical information when possible.\n",
    "    Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n",
    "    Only use the information provided in the <context> tags.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\n",
    "\n",
    "    <question>\n",
    "    {input}\n",
    "    </question>\n",
    "\n",
    "    The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "    Assistant:\"\"\"\n",
    "\n",
    "    # Create a PromptTemplate instance with the defined template and input variables\n",
    "    prompt = PromptTemplate(\n",
    "        template=PROMPT_TEMPLATE, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    print(\"Prompt Created\")\n",
    "\n",
    "    # Return the created prompt template to be used with the RAG model\n",
    "    return prompt\n",
    "\n",
    "print(create_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
